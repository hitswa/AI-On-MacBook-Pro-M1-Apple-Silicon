{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üî• Exercise 2: Implement a Simple 3-Layer Neural Network\n",
    "\n",
    "üí° **Goal:** Implement a neural network with\n",
    "\n",
    "- ‚úîÔ∏è **3 layers**: Input ‚Üí Hidden ‚Üí Output\n",
    "- ‚úîÔ∏è **Activation function**: Sigmoid\n",
    "- ‚úîÔ∏è **Backpropagation**: Train using gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.2751\n",
      "Epoch 100, Loss: 0.1410\n",
      "Epoch 200, Loss: 0.0483\n",
      "Epoch 300, Loss: 0.0210\n",
      "Epoch 400, Loss: 0.0120\n",
      "Epoch 500, Loss: 0.0080\n",
      "Epoch 600, Loss: 0.0059\n",
      "Epoch 700, Loss: 0.0046\n",
      "Epoch 800, Loss: 0.0037\n",
      "Epoch 900, Loss: 0.0031\n",
      "\n",
      "Final Predictions:\n",
      "[[0.02766161]\n",
      " [0.07528557]\n",
      " [0.92075152]\n",
      " [0.98371912]\n",
      " [0.98572941]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sigmoid activation function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Derivative of Sigmoid function\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "# Training Data\n",
    "X = np.array([[-2], [-1], [0], [1], [2]])  # Inputs\n",
    "y = np.array([[0], [0], [1], [1], [1]])    # Labels\n",
    "\n",
    "# Network Architecture: 1 input ‚Üí 2 hidden ‚Üí 1 output\n",
    "input_size = 1\n",
    "hidden_size = 2\n",
    "output_size = 1\n",
    "\n",
    "# Initialize weights and biases\n",
    "np.random.seed(42)  # For reproducibility\n",
    "W1 = np.random.randn(input_size, hidden_size)  # Input to hidden\n",
    "b1 = np.random.randn(hidden_size)\n",
    "W2 = np.random.randn(hidden_size, output_size)  # Hidden to output\n",
    "b2 = np.random.randn(output_size)\n",
    "\n",
    "learning_rate = 0.1\n",
    "epochs = 1000\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(epochs):\n",
    "    # Forward Pass\n",
    "    Z1 = np.dot(X, W1) + b1  # Input to Hidden\n",
    "    A1 = sigmoid(Z1)         # Activation function\n",
    "    Z2 = np.dot(A1, W2) + b2 # Hidden to Output\n",
    "    A2 = sigmoid(Z2)         # Final Prediction\n",
    "\n",
    "    # Compute Loss (Mean Squared Error)\n",
    "    loss = np.mean((A2 - y) ** 2)\n",
    "\n",
    "    # Backpropagation\n",
    "    dL_dA2 = 2 * (A2 - y)  # Loss derivative\n",
    "    dA2_dZ2 = sigmoid_derivative(A2)\n",
    "    dZ2_dW2 = A1\n",
    "    dZ2_dB2 = 1\n",
    "\n",
    "    dL_dW2 = np.dot(dZ2_dW2.T, dL_dA2 * dA2_dZ2)\n",
    "    dL_dB2 = np.sum(dL_dA2 * dA2_dZ2, axis=0)\n",
    "\n",
    "    dZ2_dA1 = W2\n",
    "    dA1_dZ1 = sigmoid_derivative(A1)\n",
    "    dL_dW1 = np.dot(X.T, np.dot(dL_dA2 * dA2_dZ2, dZ2_dA1.T) * dA1_dZ1)\n",
    "    dL_dB1 = np.sum(np.dot(dL_dA2 * dA2_dZ2, dZ2_dA1.T) * dA1_dZ1, axis=0)\n",
    "\n",
    "    # Update weights and biases\n",
    "    W2 -= learning_rate * dL_dW2\n",
    "    b2 -= learning_rate * dL_dB2\n",
    "    W1 -= learning_rate * dL_dW1\n",
    "    b1 -= learning_rate * dL_dB1\n",
    "\n",
    "    # Print loss every 100 epochs\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
    "\n",
    "# Final Output\n",
    "print(\"\\nFinal Predictions:\")\n",
    "output = sigmoid(np.dot(sigmoid(np.dot(X, W1) + b1), W2) + b2)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìå Analysis of Your Output\n",
    "\n",
    "‚úÖ Loss Reduction:\n",
    "\n",
    "- Epoch 0: 0.2751\n",
    "- Epoch 900: 0.0031 (almost zero, meaning the network is highly accurate) ‚úÖ Final Predictions:\n",
    "- For input -2 ‚Üí 0.0276 (almost 0, ‚úÖ correct)\n",
    "- For input -1 ‚Üí 0.0752 (closer to 0, ‚úÖ correct)\n",
    "- For input 0 ‚Üí 0.9207 (closer to 1, ‚úÖ correct)\n",
    "- For input 1 ‚Üí 0.9837 (almost 1, ‚úÖ correct)\n",
    "- For input 2 ‚Üí 0.9857 (almost 1, ‚úÖ correct)\n",
    "\n",
    "üöÄ Your network is successfully classifying the inputs!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (deep-learning-env)",
   "language": "python",
   "name": "deep-learning-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
